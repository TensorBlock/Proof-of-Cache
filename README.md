<div style="width: auto; margin-left: auto; margin-right: auto">
<img src="https://i.imgur.com/jC7kdl8.jpeg" alt="TensorBlock" style="width: 100%; min-width: 400px; display: block; margin: auto;">
</div>
<div style="display: flex; justify-content: space-between; width: 100%;">
    <div style="display: flex; flex-direction: column; align-items: flex-start;">
        <p style="margin-top: 0.5em; margin-bottom: 0em;">
            Feedback and support: TensorBlock's  <a href="https://x.com/tensorblock_aoi">Twitter/X</a>, <a href="https://t.me/TensorBlock">Telegram Group</a> and <a href="https://x.com/tensorblock_aoi">Discord server</a>
        </p>
    </div>
</div>

# Proof of Cache
**Proof of Cache (PoC)** is an **Efficient Verification Protocol** for Decentralized Inference in Large Language Models (LLMs).

Decentralized inference networks for LLMs enable the deployment of complex models across multiple machines, facilitating collaborative inference. However, ensuring computational integrity in these architectures remains challenging. Existing methods, such as redundant computation, are inefficient and costly. In this work, we introduce a novel **KV-cache sampling** approach, leveraging the deterministic internal states of LLMs to enable lightweight and efficient verification. By reducing computational redundancy and maximizing hardware parallelism, this approach significantly enhances verification efficiency. Additionally, we propose a protocol design for the verification process that ensures fairness among participants and long-term system sustainability. Finally, we discuss payoff distributions and outline potential avenues for optimizing the protocol in future work.


<p align="center">
    <img src="https://i.imgur.com/ft0Drx6.png" alt="KV-cache sampling" width="65%">
</p>
<p align="center">KV-cache sampling</p>

<p align="center">
    <img src="https://i.imgur.com/juDSaq8.png" alt="KV-cache matching" width="65%">
</p>
<p align="center">KV-cache matching</p>

## Preliminary Report
A **preliminary report** detailing our approach, methodology, and early findings is attached in this repository. We encourage you to read it for a deeper technical understanding of the PoC protocol.

## Contributing & Discussion
We welcome all forms of feedback and discussion. Please **raise an issue** in this repository to:
- Ask questions
- Suggest improvements
- Report bugs
- Discuss potential directions

We look forward to collaborating with the community to refine and optimize this protocol!
